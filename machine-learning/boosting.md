---
description: >-
  Бустинг - це дуже популярний алгоритм машинного навчання, який завоював довіру
  експертів в останні роки та набув надзвичайно широкого застовування
---

# Boosting

### Бустинг у машинному навчанні <a href="#seo-faq-pairs-what-is-boosting-in-machine-learning" id="seo-faq-pairs-what-is-boosting-in-machine-learning"></a>

Бустинг – це метод, який використовується у машинному навчанні для зменшення кількості помилок при прогностичному аналізі даних. Фахівці по роботі з даними навчають моделі машинного навчання на вже розмічених даних (тренувальних), щоб у подальшому робити прогнох на нерозмічених даних (тестових). Одна модель машинного навчання може робити помилки при прогнозуванні залежно від точності навчального набору даних. Наприклад, якщо модель ідентифікації кішок була навчена лише на зображеннях білих кішок, в окремих випадках вона може неправильно ідентифікувати чорну кішку. Бустинг намагається подолати цю проблему шляхом послідовного навчання кількох моделей для підвищення точності всієї системи.

### Чому він важливий? <a href="#seo-faq-pairs-why-is-boosting-important" id="seo-faq-pairs-why-is-boosting-important"></a>

Бустинг покращує точність прогнозування і загальну ефективність моделей шляхом модифікації (навчання) комплексу слабких моделей в одну єдину систему машинного навчання. З цього слідує, що моделі машинного навчання можна поділити на "сильні" та "слабкі".

#### "Слабкі" моделі

Слабкі моделі мають низьку точність прогнозування, яку можна порівняти з випадковим вгадуванням. Такі моделі схильні до перенавчання: вони не можуть класифікувати дані, які сильно відрізняються від вихідного набору. Наприклад, якщо навчити модель ідентифікувати кішок як тварин із загостреними вухами, вона не зможе розпізнати кішку із загнутими вухами.

#### "Сильні" моделі

Сильні моделі мають більш високу точність прогнозування. Бустинг перетворює систему слабких моделей на єдиний сильний алгоритм навчання. Наприклад, щоб розпізнати зображення кішки, він поєднує слабку модель, що класифікує гострі вуха, та іншу модель, що відповідає за котячі очі. Проаналізувавши зображення тварини на наявність загострених вух, система аналізує його ще раз для розпізнавання котячих очей. Такий підхід збільшує загальну точність системи.

### Як працює бустинг? <a href="#seo-faq-pairs-how-does-boosting-work" id="seo-faq-pairs-how-does-boosting-work"></a>

Щоб зрозуміти принцип роботи алгоритму бустингу, необхідно розібратися, як моделі машинного навчання приймають рішення. Незважаючи на різноманітність варіантів реалізації, фахівці по роботі з даними часто використовують саме поєднання бустингу із деревами рішень:

#### Дерева рішень

Деревья решений — это структуры данных в машинном обучении, разделяющие набор данных на меньшие подмножества в зависимости от их характеристик. Идея заключается в том, что деревья решений многократно разделяют данные, пока не останется только один класс. Например, дерево может задать ряд вопросов с ответами «да» или «нет» и разделить данные на категории при каждом шаге.

#### Бустинг — ансамблевый метод

Дерева рішень — це структури даних у машинному навчанні, що поділяють набір даних на менші підмножини залежно від своїх характеристик. Ідея полягає у тому, що дерева рішень багаторазово поділяють дані, доки не залишиться лише один клас. Наприклад, дерево може поставити низку запитань із відповідями «так» чи «ні» та розділити дані на категорії при кожному кроці.

#### Відмінність бустингу від бегінгу

Бустинг і бегінг — два поширені ансамблеві методи, що підвищують точність прогнозування. Основна відмінність між ними – _метод навчання_. У випадку _**бегінгу**_ фахівці по роботі з даними підвищують точність слабких моделей, паралельно навчаючи деякі з них на різних наборах даних. _**Бустинг**_ навчає слабкі моделі послідовно.

<figure><img src="../.gitbook/assets/image (11).png" alt=""><figcaption><p><a href="https://aws.amazon.com/ru/what-is/boosting/">https://aws.amazon.com/ru/what-is/boosting/</a></p></figcaption></figure>

### Як відбувається навчання при бустингу? <a href="#seo-faq-pairs-how-is-training-in-boosting-done" id="seo-faq-pairs-how-is-training-in-boosting-done"></a>

Метод навчання залежить від типу бустингу, що називається алгоритмом. При цьому алгоритм виконує такі спільні кроки для навчання моделі:

#### Крок 1

Алгоритм бустингу надає рівну вагу кожній вибірці даних. Він передає дані першій моделі, яка називається базовим алгоритмом. Для кожної вибірки даних базовий алгоритм робить прогнози.

#### Крок 2

Алгоритм бустингу оцінює прогнози моделі та збільшує вагу вибірок із значною помилкою. Також вага надається на основі продуктивності моделі. Модель із кращими прогнозами матиме великий вплив на остаточне рішення.

#### Крок 3

Алгоритм передає зважені дані до наступного дерева рішень.

#### Крок 4

Алгоритм повторює кроки 2 і 3 до тих пір, поки помилки навчання не опустяться нижче за певний поріг.

### Які види бустингу існують? <a href="#seo-faq-pairs-what-are-the-types-of-boosting" id="seo-faq-pairs-what-are-the-types-of-boosting"></a>

Нижче наведено три основні види бустингу:

#### Адаптивний бустинг

Адаптивний бустинг (AdaBoost) - одна з найраніших моделей бустингу. Він адаптується та самостійно коригує класифікатори у кожній ітерації бустингу. AdaBoost спочатку надає однакову вагу кожному набору даних. Потім він автоматично коригує ваги точок вибірки після кожного кроку на дереві рішень. Елементи, які були класифіковані невірно, набувають більшої ваги у наступній ітерації. Процес повторюється, поки залишкова помилка чи різниця між фактичними і прогнозованими значеннями не опуститься нижче допустимого рівня. AdaBoost можна використовувати з багатьма предикторами. Крім того, він менш чутливий, ніж інші алгоритми бустингу. AdaBoost не є таким ефективним при наявності кореляції між факторами або використанні даних великої розмірності. Хоча в цілому, AdaBoost  добре справляється із завданнями класифікації.

#### Градієнтий бустинг

Градіентний бустинг (GB) схожий на AdaBoost: він також є методом послідовного навчання. Різниця між AdaBoost та GB у тому, що GB не присвоює неправильно класифікованим елементам більшу вагу. Натомість програмне забезпечення GB оптимізує функцію втрат через послідовне генерування базових моделей, внаслідок чого поточна базова модель завжди стає ефективнішою за попередню. На відміну від AdaBoost, метод GB намагається одразу генерувати точні результати, а не виправляти помилки. Саме тому метод GB дає більш точні результати. Градієнтний бустинг підходить як для задач класифікації, так і для регресії.

#### Екстремальний градієнтний бустинг

Екстремальний градієнтний бустинг (XGBoost) у різний спосіб покращує градієнтний бустинг, фокусуючись на швидкості обчислень та масштабах моделі. XGBoost розроблено для ефективної багатоядерної паралельної обробки прямо під час навчання. Цей алгоритм бустингу є ефективним інструментом роботи з великими даними. Ключовими особливостями XGBoost є розпаралелювання, розподілені обчислення, оптимізація кешу та зовнішні обчислення.

### В чому полягають основні переваги бустингу? <a href="#seo-faq-pairs-what-are-the-benefits-of-boosting" id="seo-faq-pairs-what-are-the-benefits-of-boosting"></a>

Основными перевагами бустингу є:

#### Простота реализації

Бустинг має прості для розуміння та інтерпретації алгоритми, здатні вчитися на своїх помилках. Ці алгоритми вимагають попередньої обробки даних, і навіть мають вбудовані процедури обробки відсутніх значень. Крім того, більшість бібліотек для реалізації алгоритмів бустингу мають безліч параметрів, що дозволяють точно задавати налаштування.

#### Менший bias (зміщення)

Зміщення – це наявність невизначеності чи неточності у результатах машинного навчання. Алгоритми бустингу поєднують кілька слабких моделей у послідовний метод, що ітеративно покращує спостереження. Такий підхід допомагає зменшити високе усунення, яке поширене в моделях машинного навчання.

#### Ефективність алгоритмів

Алгоритми бустингу фокусуються на елементах, що підвищують точність прогнозування під час навчання. Вони здатні зменшувати кількість атрибутів даних та ефективно обробляти великі набори.

### Які недоліки бустингу? <a href="#seo-faq-pairs-what-are-the-challenges-of-boosting" id="seo-faq-pairs-what-are-the-challenges-of-boosting"></a>

Нижче наведено основні недоліки бустингу:

#### Вразливість до викидів та аномалій

Моделі бустингу вразливі до викидів чи значень даних, що відрізняється від інших наборів даних (аномалій). Викиди можуть суттєво спотворювати результати, оскільки кожна модель намагається виправити помилки попередньої.

#### Реалізації в режимі реального часу

Оскільки цей алгоритм складніший за багато інших, тому при реалізації бустингу в режимі реального часу можуть виникнути труднощі. Бустинг виявляє високу адаптивність, тому можна використовувати різноманітні параметри моделі, які безпосередньо впливають на її продуктивність.
